{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "24yCLLjstPjb"
   },
   "source": [
    "## Part 1: Existing Machine Learning Services\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/peckjon/hosting-ml-as-microservice/blob/master/part1/score_reviews_via_service.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jwR4_2_otPjg"
   },
   "source": [
    "### Obtain labelled reviews\n",
    "\n",
    "In order to test any of the sentiment analysis APIs, we need a labelled dataset of reviews and their sentiment polarity. We'll use NLTK to download the movie_reviews corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zPOhVzNrtPjj",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from nltk import download\n",
    "import boto3\n",
    "import sys\n",
    "\n",
    "download('movie_reviews')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zPd-EWKptPjw"
   },
   "source": [
    "### Load the data\n",
    "\n",
    "The files in movie_reviews have already been divided into two sets: positive ('pos') and negative ('neg'), so we can load the raw text of the reviews into two lists, one for each polarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DuuqNmcmtPjy"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import movie_reviews\n",
    "\n",
    "# extract words from reviews, pair with label\n",
    "\n",
    "reviews_pos = []\n",
    "\n",
    "for fileid in movie_reviews.fileids('pos'):\n",
    "    review = movie_reviews.raw(fileid)\n",
    "    reviews_pos.append(review)\n",
    "\n",
    "reviews_neg = []\n",
    "for fileid in movie_reviews.fileids('neg'):\n",
    "    review = movie_reviews.raw(fileid)\n",
    "    reviews_neg.append(review)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab_type": "text",
    "id": "TMy_1Mg4tPj-"
   },
   "outputs": [],
   "source": [
    "### Connect to the scoring API\n",
    "\n",
    "Fill in this function with code that connects to one of these APIs, and uses it to score a single review:\n",
    "\n",
    "* [Amazon Comprehend: Detect Sentiment](https://docs.aws.amazon.com/comprehend/latest/dg/API_DetectSentiment.html)\n",
    "* [Google Natural Language: Analyzing Sentiment](https://cloud.google.com/natural-language/docs/analyzing-sentiment)\n",
    "* [Azure Cognitive Services: Sentiment Analysis](https://docs.microsoft.com/en-us/azure/cognitive-services/text-analytics/how-tos/text-analytics-how-to-sentiment-analysis)\n",
    "* [Algorithmia: Sentiment Analysis](https://algorithmia.com/algorithms/nlp/SentimentAnalysis)\n",
    "\n",
    "Your function must return either 'pos' or 'neg', so you'll need to make some decisions about how to map the results of the API call to one of these values. For example, Amazon Comprehend can return \"NEUTRAL\" or \"MIXED\" for the Sentiment -- if this happens, you may with to inspect the numeric values under the SentimentScore to see whether it leans toward positive or negative.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HSWexF18tPkA"
   },
   "outputs": [],
   "source": [
    "\n",
    "def score_review(review):\n",
    "    comprehend_client = boto3.client('comprehend')\n",
    "    response = comprehend_client.detect_sentiment(Text=review,LanguageCode=\"en\")\n",
    "    response_sentiment = response['Sentiment']\n",
    "    \n",
    "    if response_sentiment == \"POSITIVE\":\n",
    "        review_sentiment = \"pos\"\n",
    "    elif response_sentiment == 'NEGATIVE':\n",
    "        review_sentiment = 'neg'\n",
    "    elif response['SentimentScore']['Positive'] > response['SentimentScore']['Negative']:\n",
    "        review_sentiment = 'pos'\n",
    "    else:\n",
    "        review_sentiment = 'neg'\n",
    "    # TBD: call the service and return 'pos' or 'neg'\n",
    "    \n",
    "    return review_sentiment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "egteKGkJtPkL"
   },
   "source": [
    "### Score each review\n",
    "\n",
    "Now, we can use the function you defined to score each of the reviews.\n",
    "\n",
    "#### *Note on Testing*\n",
    "\n",
    "While most of the services listed have free tiers they may be limited to a few thousand requests per week or month, depending on the service. On some platforms you may be billed after reaching that limit. For this reason it is recommended to first test on a smaller set of the reviews, `subset_pos` and `subset_neg`. Once you're happy with your code swap those subsets for the full review sets `reviews_pos` and `reviews_neg`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mWkdNH_ktPkN"
   },
   "outputs": [],
   "source": [
    "# Create 2 smaller subsets for testing\n",
    "# Amazon Comprehend only accepts text up to 5000 bytes\n",
    "filtered_reviews_pos = [ rp for rp in reviews_pos if sys.getsizeof(rp) < 5000 ]\n",
    "filtered_reviews_neg = [ rp for rp in reviews_neg if sys.getsizeof(rp) < 5000 ]\n",
    "subset_pos = filtered_reviews_pos\n",
    "subset_neg = filtered_reviews_neg\n",
    "\n",
    "results_pos = []\n",
    "# When comfortable with results switch `subset_pos` to reviews_post`\n",
    "for review in subset_pos:\n",
    "    result = score_review(review)\n",
    "    results_pos.append(result)\n",
    "    \n",
    "results_neg = []\n",
    "# When comfortable with results switch `subset_neg` to reviews_neg`\n",
    "for review in subset_neg:\n",
    "    result = score_review(review)\n",
    "    results_neg.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X7W95r2BtPkf"
   },
   "source": [
    "### Calculate accuracy\n",
    "\n",
    "For each of our known positive reviews, we can count the number which our function scored as 'pos', and use this to calculate the % accuracy. We repeaty this for negative reviews, and also for overall accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ft71Rv6-tPkh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "483\n",
      "Positive reviews: 65.18218623481782% correct\n",
      "Negative reviews: 69.6470588235294% correct\n",
      "Overall accuracy: 67.56756756756756% correct\n"
     ]
    }
   ],
   "source": [
    "\n",
    "correct_pos = results_pos.count('pos')\n",
    "accuracy_pos = float(correct_pos) / len(results_pos)\n",
    "\n",
    "correct_neg = results_neg.count('neg')\n",
    "accuracy_neg = float(correct_neg) / len(results_neg)\n",
    "\n",
    "correct_all = correct_pos + correct_neg\n",
    "accuracy_all = float(correct_all) / (len(results_pos)+len(results_neg))\n",
    "print('Positive reviews: {}% correct'.format(accuracy_pos*100))\n",
    "print('Negative reviews: {}% correct'.format(accuracy_neg*100))\n",
    "print('Overall accuracy: {}% correct'.format(accuracy_all*100))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "name": "score_reviews_via_service.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
